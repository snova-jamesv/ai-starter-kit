{
  "Model Architecture": {
    "Llama 2 7B": "Advanced architecture with Grouped-Query Attention, optimized for alignment with human preferences.",
    "Mistral 7B": "Efficiency-focused with Grouped-Query Attention and specialized tokenizer for better context handling.",
    "DeepSeek Coder": "Efficiency optimized with Pre-Norm structure, Rotary Embedding, and adjustable layers.",
    "Falcon 40B": "Large 40 billion parameter model trained on diverse datasets for broad knowledge.",
    "GPT 3.5T": "Enhanced transformer architecture for improved context management and task performance."
  },
  "Architecture Prompting Implications": {
    "Llama 2 7B": "Prompts should be structured to take advantage of its supervised fine-tuning and reinforcement learning from human feedback. Prompts that are more aligned with human conversational styles and preferences work well.",
    "Mistral 7B": "Efficiency-focused prompts work well, given Mistral's design to optimize computational resources. Being concise and clear in your requests.",
    "DeepSeek Coder": "Leveraging its Rotary Embedding for positional encoding suggests that prompts with more structured and positionally significant information might be handled more effectively.",
    "Falcon 40B": "Given high parameter count, prompts can be more complex and multifaceted, expecting detailed and nuanced responses.\nThe model’s extensive training on a broad range of tokens improves performance on less common or more specialized subjects.",
    "Bloom": "Prompting for BLOOM should leverage its zero-shot generalization by providing concise, context-rich queries. Its ALiBi positional embeddings allow for effective handling of longer and more complex sequences, enabling nuanced and in-depth responses.",
    "GPT 3.5T": "Allows for effective handling of complex prompts and nuanced contexts, supporting more natural interactions. Its ability to process detailed inputs makes it suitable for a variety of conversational and content generation applications."
  },
  "Heuristic Guidance": {
    "Llama 2 7B": "Llama 2 responds effectively to concise system prompts that direct its persona or response boundaries. This includes prompts like \"Act as if…\", \"You are…\", \"Always/Never…\", or \"Speak like…\". ",
    "Mistral 7B": "Mistral has specific requirements for its prompt structure to achieve optimal outputs. When using Mistral-7B-Instruct, it is recommended to use a chat template that includes special tokens for the beginning and end of strings (BOS and EOS), along with regular strings for instructions. For example, the template might look like <s>[INST] Instruction [/INST] Model answer</s>[INST] Follow-up instruction [/INST]. This structure helps the model understand the context and respond appropriately. ",
    "DeepSeek Coder": "TBC",
    "Falcon 40B": "TBC",
    "Bloom": "TBC",
    "GPT 3.5T": "Prompts should be clear and contextual, taking advantage of GPT-3.5 Turbo's improved comprehension. It performs well with detailed instructions and can manage complex scenarios, making it a solid generalist."
  },
  "References": {
    "Llama 2 7B": "https://replicate.com/blog/how-to-prompt-llama\nhttps://arxiv.org/pdf/2307.09288.pdf\nhttps://huggingface.co/blog/llama2#how-to-prompt-llama-2\nhttps://huggingface.co/docs/transformers/main/model_doc/llama2",
    "Mistral 7B": "https://medium.com/dair-ai/papers-explained-mistral-7b-b9632dedf580\nhttps://arxiv.org/pdf/2310.06825.pdf\nhttps://www.promptingguide.ai/models/mistral-7b",
    "DeepSeek Coder": "https://arxiv.org/pdf/2401.02954v1.pdf",
    "Falcon 40B": "https://arxiv.org/pdf/2311.16867.pdf\nhttps://www.prompthub.us/blog/10-best-practices-for-prompt-engineering-with-any-model",
    "Bloom": "https://arxiv.org/pdf/2211.05100.pdf",
    "GPT 3.5T": ""
  },
  "Meta Tag Format": {
    "Llama 2 7B": "[INST] <<SYS>>  \n{system_prompt}  \n<</SYS>>  \n{user_prompt}  \n[/INST]",
    "Mistral 7B": "<s> [INST] {system_prompt}  \n{few_shot_example_input}  [/INST]  \n{few_shot_example_ouput}  \n</s> [INST] {user_prompt}  [/INST]",
    "DeepSeek Coder": "[{\"role\": \"user\", \"content\": \"instruction\"}]",
    "Falcon 40B": "No special meta tags known; classify input with natural language, e.g.  \nInstructions:  \nQuestion:",
    "Bloom": "No formatting guidelines found, references only mentioned natural language input classification",
    "GPT 3.5T": "System prompt inaccessible, but input can be classified using natural language."
  },
  "General Assistant": {
    "Llama 2 7B": "[INST] <<SYS>> You are a helpful, respectful, positive, and honest assistant. Your answers should not include any unsafe, unethical, or illegal content. If you don't understand the question or don't know the answer, please don't share false information. <</SYS>>\n\nHow can I write better prompts for large language models? [/INST]",
    "Mistral 7B": "<s> [INST] You are a helpful, respectful, positive, and honest assistant. Your answers should not include any unsafe, unethical, or illegal content. If you don't understand the question or don't know the answer, please don't share false information. </s> [/INST]\n\n[INST] How can I write better prompts for large language models? [/INST] ",
    "DeepSeek Coder": "[{\"role\": \"user\",  \n \"content\": \"show me how to combine strings in python\"}]",
    "Falcon 40B": "System: You are a helpful, respectful, positive, and honest assistant. Your answers should not include any unsafe, unethical, or illegal content. If you don't understand the question or don't know the answer, please don't share false information.  \n User: How can I write better prompts for large language models?",
    "Bloom": "System: You are a helpful, respectful, positive, and honest assistant. Your answers should not include any unsafe, unethical, or illegal content. If you don't understand the question or don't know the answer, please don't share false information.  \n User: How can I write better prompts for large language models?",
    "GPT 3.5T": "System: You are a helpful, respectful, positive, and honest assistant. Your answers should not include any unsafe, unethical, or illegal content. If you don't understand the question or don't know the answer, please don't share false information.  \n User: How can I write better prompts for large language models?"
  },
  "Document Search": {
    "Llama 2 7B": "[INST] <<SYS>> Use the following pieces of context to answer the question at the end. If the answer is not in context for answering, say that you don't know, don't try to make up an answer or provide an answer not extracted from provided context. <</SYS>>\nContext: Early Account Closure Fee $30 (if account is closed within 6 months of opening) \nReplacement of ATM Card $5 per card \nReplacement Of Lost Passbook $15 per passbook \nQuestion: I lost my ATM card. How much will it cost to replace it? [/INST]",
    "Mistral 7B": "<s> [INST] Use the following pieces of context to answer the question at the end. If the answer is not in context for answering, say that you don't know, don't try to make up an answer or provide an answer not extracted from provided context. [/INST] Context: Early Account Closure Fee $30 (if account is closed within 6 months of opening) \nReplacement of ATM Card $5 per card \nReplacement Of Lost Passbook $15 per passbook </s> \n[INST] Question: I lost my ATM card. How much will it cost to replace it? [/INST]",
    "DeepSeek Coder": "[{\"role\": \"user\",  \n \"content\": \"show me how to combine strings in python\"}]",
    "Falcon 40B": "System: Use the following pieces of context to answer the question at the end. If the answer is not in context for answering, say that you don't know, don't try to make up an answer or provide an answer not extracted from provided context. \nContext: Early Account Closure Fee $30 (if account is closed within 6 months of opening) \nReplacement of ATM Card $5 per card \nReplacement Of Lost Passbook $15 per passbook \nQuestion: I lost my ATM card. How much will it cost to replace it? ",
    "Bloom": "System: Use the following pieces of context to answer the question at the end. If the answer is not in context for answering, say that you don't know, don't try to make up an answer or provide an answer not extracted from provided context. \nContext: Early Account Closure Fee $30 (if account is closed within 6 months of opening) \nReplacement of ATM Card $5 per card \nReplacement Of Lost Passbook $15 per passbook \nQuestion: I lost my ATM card. How much will it cost to replace it?  ",
    "GPT 3.5T": "System: Use the following pieces of context to answer the question at the end. If the answer is not in context for answering, say that you don't know, don't try to make up an answer or provide an answer not extracted from provided context. \nContext: Early Account Closure Fee $30 (if account is closed within 6 months of opening) \nReplacement of ATM Card $5 per card \nReplacement Of Lost Passbook $15 per passbook \nQuestion: I lost my ATM card. How much will it cost to replace it?  "
  },
  "Product Selection": {
    "Llama 2 7B": "[INST] <<SYS>> You are an electrical engineer ai assistant.  You will be given context that will help answer a question.  You will interpret the context for useful information that will answer the question.  Provide concise, helpful, technical information (focusing on numerical information).  <</SYS>> [/INST] \n    Here is the question and context: \n\n    question: 'what is the switching frequency of max20710?'\n    contexts: VREF  Range | | See Table 8 for accuracy vs. �REF VREF (Note 6 ) | 0.6016 | | 1.0 | V | | FEEDBACK LOOP | | | | | | | | Integrator Recovery-Time Constant | tREC tREC  | | | 20 | | �s μs | | Gain (see the Control Loop Stability section for details) | RGAIN RGAIN  | Selected by R_SELB or PMBus ( ( Note 5,6,7,8) 5,6,7,8) | 0.72 | 0.9 | 1.1 | mV/A mV/A | | | | | 1.4 | 1.8 | 2.2 | | | | | | 2.9 | 3.6 | 4.3 | | | SWITCHING FREQUENCY | | | | | | | | Switching Frequency | ��� fSW  | 400kHz/600kHz/800kHz 400kHz/600kHz/800kHz selected by C_SELB; other values are set through PMBus (Note 6 ) | | 400 | | kHz kHz | | | | | | 500 | | | | | | | | 600 | | | | | | | | 700 | | | | | | | | 800 | | | | | | | | 900 | | | | Switching Frequency Accuracy | | ( ( Note 5,7,8) 5,7,8) | -20 | | +20 | % % | | INPUT PROTECTION | | | | | | | | Rising VDDH VDDH  UVLO Threshold | VDDH UVLO | (Note 5) | | 4.25 | 4.47 | V | | Falling VDDH VDDH  UVLO Threshold | | | 3.7 | 3.9 | | | | Hysteresis | | | | 350 | | mV mV |\n\n    [INST] Given the context you received, answer the question.  Please do not infer anything if the question cannot be deduced from the context or make anything up; simply state you cannot find the information. [/INST]\n\n    Sure, here is the answer to the question:",
    "Mistral 7B": "<s> [INST] You are an electrical engineer ai assistant.  You will be given context that will help answer a question.  You will interpret the context for useful information that will answer the question.  Provide concise, helpful, technical information (focusing on numerical information).  [/INST] \n    Here is the question and context: \n\n    question: 'what is the switching frequency of max20710?'\n    contexts: VREF  Range | | See Table 8 for accuracy vs. �REF VREF (Note 6 ) | 0.6016 | | 1.0 | V | | FEEDBACK LOOP | | | | | | | | Integrator Recovery-Time Constant | tREC tREC  | | | 20 | | �s μs | | Gain (see the Control Loop Stability section for details) | RGAIN RGAIN  | Selected by R_SELB or PMBus ( ( Note 5,6,7,8) 5,6,7,8) | 0.72 | 0.9 | 1.1 | mV/A mV/A | | | | | 1.4 | 1.8 | 2.2 | | | | | | 2.9 | 3.6 | 4.3 | | | SWITCHING FREQUENCY | | | | | | | | Switching Frequency | ��� fSW  | 400kHz/600kHz/800kHz 400kHz/600kHz/800kHz selected by C_SELB; other values are set through PMBus (Note 6 ) | | 400 | | kHz kHz | | | | | | 500 | | | | | | | | 600 | | | | | | | | 700 | | | | | | | | 800 | | | | | | | | 900 | | | | Switching Frequency Accuracy | | ( ( Note 5,7,8) 5,7,8) | -20 | | +20 | % % | | INPUT PROTECTION | | | | | | | | Rising VDDH VDDH  UVLO Threshold | VDDH UVLO | (Note 5) | | 4.25 | 4.47 | V | | Falling VDDH VDDH  UVLO Threshold | | | 3.7 | 3.9 | | | | Hysteresis | | | | 350 | | mV mV |\n\n    [INST] Given the context you received, answer the question.  Please do not infer anything if the question cannot be deduced from the context or make anything up; simply state you cannot find the information. </s> [INST]\n\n    Sure, here is the answer to the question: [/INST]",
    "DeepSeek Coder": "[{\"role\": \"user\",  \n \"content\": \"show me how to combine strings in python\"}]",
    "Falcon 40B": "You are an electrical engineer ai assistant.  You will be given context that will help answer a questions.  You will interpret the context for useful information that will answer the question.  Provides concise, helpful, technical information (focusing on numerical information).  <</SYS>>\n\n    You will be given context that will help you answer a question: [/INST] \n    Here is the question and context: \n\n    question: 'what is the switching frequency of max20710?'\n    contexts: VREF  Range | | See Table 8 for accuracy vs. �REF VREF (Note 6 ) | 0.6016 | | 1.0 | V | | FEEDBACK LOOP | | | | | | | | Integrator Recovery-Time Constant | tREC tREC  | | | 20 | | �s μs | | Gain (see the Control Loop Stability section for details) | RGAIN RGAIN  | Selected by R_SELB or PMBus ( ( Note 5,6,7,8) 5,6,7,8) | 0.72 | 0.9 | 1.1 | mV/A mV/A | | | | | 1.4 | 1.8 | 2.2 | | | | | | 2.9 | 3.6 | 4.3 | | | SWITCHING FREQUENCY | | | | | | | | Switching Frequency | ��� fSW  | 400kHz/600kHz/800kHz 400kHz/600kHz/800kHz selected by C_SELB; other values are set through PMBus (Note 6 ) | | 400 | | kHz kHz | | | | | | 500 | | | | | | | | 600 | | | | | | | | 700 | | | | | | | | 800 | | | | | | | | 900 | | | | Switching Frequency Accuracy | | ( ( Note 5,7,8) 5,7,8) | -20 | | +20 | % % | | INPUT PROTECTION | | | | | | | | Rising VDDH VDDH  UVLO Threshold | VDDH UVLO | (Note 5) | | 4.25 | 4.47 | V | | Falling VDDH VDDH  UVLO Threshold | | | 3.7 | 3.9 | | | | Hysteresis | | | | 350 | | mV mV |\n\n     Given the context you received, answer the question.  Please do not infer anything if the question cannot be deduced from the context or make anything up; simply state you cannot find the information. \n\n    Sure, here is the answer to the question:",
    "Bloom": "You are an electrical engineer ai assistant.  You will be given context that will help answer a questions.  You will interpret the context for useful information that will answer the question.  Provides concise, helpful, technical information (focusing on numerical information).  <</SYS>>\n\n    You will be given context that will help you answer a question: [/INST] \n    Here is the question and context: \n\n    question: 'what is the switching frequency of max20710?'\n    contexts: VREF  Range | | See Table 8 for accuracy vs. �REF VREF (Note 6 ) | 0.6016 | | 1.0 | V | | FEEDBACK LOOP | | | | | | | | Integrator Recovery-Time Constant | tREC tREC  | | | 20 | | �s μs | | Gain (see the Control Loop Stability section for details) | RGAIN RGAIN  | Selected by R_SELB or PMBus ( ( Note 5,6,7,8) 5,6,7,8) | 0.72 | 0.9 | 1.1 | mV/A mV/A | | | | | 1.4 | 1.8 | 2.2 | | | | | | 2.9 | 3.6 | 4.3 | | | SWITCHING FREQUENCY | | | | | | | | Switching Frequency | ��� fSW  | 400kHz/600kHz/800kHz 400kHz/600kHz/800kHz selected by C_SELB; other values are set through PMBus (Note 6 ) | | 400 | | kHz kHz | | | | | | 500 | | | | | | | | 600 | | | | | | | | 700 | | | | | | | | 800 | | | | | | | | 900 | | | | Switching Frequency Accuracy | | ( ( Note 5,7,8) 5,7,8) | -20 | | +20 | % % | | INPUT PROTECTION | | | | | | | | Rising VDDH VDDH  UVLO Threshold | VDDH UVLO | (Note 5) | | 4.25 | 4.47 | V | | Falling VDDH VDDH  UVLO Threshold | | | 3.7 | 3.9 | | | | Hysteresis | | | | 350 | | mV mV |\n\n     Given the context you received, answer the question.  Please do not infer anything if the question cannot be deduced from the context or make anything up; simply state you cannot find the information. \n\n    Sure, here is the answer to the question:",
    "GPT 3.5T": "You are an electrical engineer ai assistant.  You will be given context that will help answer a questions.  You will interpret the context for useful information that will answer the question.  Provides concise, helpful, technical information (focusing on numerical information).  <</SYS>>\n\n    You will be given context that will help you answer a question: [/INST] \n    Here is the question and context: \n\n    question: 'what is the switching frequency of max20710?'\n    contexts: VREF  Range | | See Table 8 for accuracy vs. �REF VREF (Note 6 ) | 0.6016 | | 1.0 | V | | FEEDBACK LOOP | | | | | | | | Integrator Recovery-Time Constant | tREC tREC  | | | 20 | | �s μs | | Gain (see the Control Loop Stability section for details) | RGAIN RGAIN  | Selected by R_SELB or PMBus ( ( Note 5,6,7,8) 5,6,7,8) | 0.72 | 0.9 | 1.1 | mV/A mV/A | | | | | 1.4 | 1.8 | 2.2 | | | | | | 2.9 | 3.6 | 4.3 | | | SWITCHING FREQUENCY | | | | | | | | Switching Frequency | ��� fSW  | 400kHz/600kHz/800kHz 400kHz/600kHz/800kHz selected by C_SELB; other values are set through PMBus (Note 6 ) | | 400 | | kHz kHz | | | | | | 500 | | | | | | | | 600 | | | | | | | | 700 | | | | | | | | 800 | | | | | | | | 900 | | | | Switching Frequency Accuracy | | ( ( Note 5,7,8) 5,7,8) | -20 | | +20 | % % | | INPUT PROTECTION | | | | | | | | Rising VDDH VDDH  UVLO Threshold | VDDH UVLO | (Note 5) | | 4.25 | 4.47 | V | | Falling VDDH VDDH  UVLO Threshold | | | 3.7 | 3.9 | | | | Hysteresis | | | | 350 | | mV mV |\n\n     Given the context you received, answer the question.  Please do not infer anything if the question cannot be deduced from the context or make anything up; simply state you cannot find the information. \n\n    Sure, here is the answer to the question:"
  },
  "Code Generation": {
    "Llama 2 7B": "[INST] <<SYS>> You are a helpful code assistant. Generate a valid JSON object based on the inpput. \nExample: name: John lastname: Smith address: #1 Samuel St. would be converted to:\n{\n\"\"address\"\": \"\"#1 Samuel St.\"\",\n\"\"lastname\"\": \"\"Smith\"\",\n\"\"name\"\": \"\"John\"\"\n} <</SYS>>\n[INST] Input: name: Ted lastname: Pot address: #1 Bisson St. [/INST]",
    "Mistral 7B": "<s> [INST] You are a helpful code assistant. Generate a valid JSON object based on the inpput. \nExample: name: John lastname: Smith address: #1 Samuel St. would be converted to: [/INST]\n{\n\"\"address\"\": \"\"#1 Samuel St.\"\",\n\"\"lastname\"\": \"\"Smith\"\",\n\"\"name\"\": \"\"John\"\"\n} </s>\n[INST] Input: name: Ted lastname: Pot address: #1 Bisson St. [/INST]",
    "DeepSeek Coder": "[{\"role\": \"user\",  \n \"content\": \"show me how to combine strings in python\"}]",
    "Falcon 40B": "Task: You are a helpful code assistant. Generate a valid JSON object based on the inpput. \nExample: name: John lastname: Smith address: #1 Samuel St. would be converted to:\n{\n\"\"address\"\": \"\"#1 Samuel St.\"\",\n\"\"lastname\"\": \"\"Smith\"\",\n\"\"name\"\": \"\"John\"\"\n}\nInput: name: Ted lastname: Pot address: #1 Bisson St.",
    "Bloom": "Task: You are a helpful code assistant. Generate a valid JSON object based on the inpput. \nExample: name: John lastname: Smith address: #1 Samuel St. would be converted to:\n{\n\"\"address\"\": \"\"#1 Samuel St.\"\",\n\"\"lastname\"\": \"\"Smith\"\",\n\"\"name\"\": \"\"John\"\"\n}\nInput: name: Ted lastname: Pot address: #1 Bisson St.",
    "GPT 3.5T": "Task: You are a helpful code assistant. Generate a valid JSON object based on the inpput. \nExample: name: John lastname: Smith address: #1 Samuel St. would be converted to:\n{\n\"\"address\"\": \"\"#1 Samuel St.\"\",\n\"\"lastname\"\": \"\"Smith\"\",\n\"\"name\"\": \"\"John\"\"\n}\nInput: name: Ted lastname: Pot address: #1 Bisson St."
  }
}